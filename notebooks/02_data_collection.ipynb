{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Collection\n",
    "Phase 2: S&P 500 ëŒ€ê·œëª¨ ë°ì´í„° ìˆ˜ì§‘\n",
    "\n",
    "**ëª©í‘œ:**\n",
    "- S&P 500 ì „ì²´ ì¢…ëª© (503ê°œ) ë°ì´í„° ìˆ˜ì§‘\n",
    "- ê°€ê²© ë°ì´í„°: 10ë…„ì¹˜\n",
    "- ì¬ë¬´ì œí‘œ: ì—°ê°„/ë¶„ê¸°\n",
    "- ì¢…ëª©ë³„ ë°ì´í„° ì‹œì‘ ì—°ë„ ì €ì¥ (ë™ì  í•„í„°ë§ìš©)\n",
    "\n",
    "**ì˜ˆìƒ ì†Œìš” ì‹œê°„:** 30~50ë¶„"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. í™˜ê²½ ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend ê²½ë¡œ: /Users/kuka/LongArc/backend\n",
      "ë°ì´í„° ë¡œë“œ ê²½ë¡œ: /Users/kuka/LongArc/data/raw\n",
      "ê²°ê³¼ ì €ì¥ ê²½ë¡œ: /Users/kuka/5X Finder/data/raw\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "\n",
    "# === ê²½ë¡œ ì„¤ì • ===\n",
    "# ì†ŒìŠ¤ ì½”ë“œ ê²½ë¡œ (LongArc)\n",
    "backend_path = '/Users/kuka/LongArc/backend'\n",
    "if backend_path not in sys.path:\n",
    "    sys.path.insert(0, backend_path)\n",
    "\n",
    "# ê¸°ì¡´ ë°ì´í„° ë¡œë“œ ê²½ë¡œ (LongArc - ì´ë¯¸ ìˆ˜ì§‘ëœ ë°ì´í„°)\n",
    "source_dir = '/Users/kuka/LongArc/data/raw'\n",
    "\n",
    "# ê²°ê³¼ ì €ì¥ ê²½ë¡œ (5X Finder - ìƒˆ í”„ë¡œì íŠ¸)\n",
    "output_dir = '/Users/kuka/5X Finder/data/raw'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "print(f\"Backend ê²½ë¡œ: {backend_path}\")\n",
    "print(f\"ë°ì´í„° ë¡œë“œ ê²½ë¡œ: {source_dir}\")\n",
    "print(f\"ê²°ê³¼ ì €ì¥ ê²½ë¡œ: {output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from data.collector import DataCollector\n",
    "from data.universe import Universe\n",
    "from features.calculator import FeatureCalculator\n",
    "\n",
    "print(\"âœ… ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ìœ ë‹ˆë²„ìŠ¤ ë¡œë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S&P 500: 503ê°œ\n",
      "ì²˜ìŒ 10ê°œ: ['MMM', 'AOS', 'ABT', 'ABBV', 'ACN', 'ADBE', 'AMD', 'AES', 'AFL', 'A']\n"
     ]
    }
   ],
   "source": [
    "from data.universe import Universe\n",
    "from data.collector import DataCollector\n",
    "\n",
    "universe = Universe()\n",
    "collector = DataCollector()\n",
    "\n",
    "# S&P 500 ì¢…ëª© ë¡œë“œ\n",
    "sp500 = universe.get_sp500_tickers()\n",
    "print(f\"S&P 500: {len(sp500)}ê°œ\")\n",
    "print(f\"ì²˜ìŒ 10ê°œ: {sp500[:10]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. ì¢…ëª©ë³„ ë°ì´í„° ë²”ìœ„ ìŠ¤ìº”\n",
    "\n",
    "### ì™œ í•˜ëŠ”ê°€?\n",
    "**ë™ì  í•„í„°ë§**ì„ ìœ„í•´ ê° ì¢…ëª©ì˜ ë°ì´í„° ì‹œì‘ ì—°ë„ë¥¼ ì•Œì•„ì•¼ í•¨.\n",
    "- META: 2012ë…„ ìƒì¥ â†’ 2012ë…„ë¶€í„° ì‚¬ìš© ê°€ëŠ¥\n",
    "- UBER: 2019ë…„ ìƒì¥ â†’ 2019ë…„ë¶€í„° ì‚¬ìš© ê°€ëŠ¥\n",
    "- AAPL: 1980ë…„ ìƒì¥ â†’ 2010ë…„ë¶€í„° ì‚¬ìš© ê°€ëŠ¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ê¸°ì¡´ ìŠ¤ìº” ê²°ê³¼ ë¡œë“œ: 502ê°œ ì¢…ëª©\n"
     ]
    }
   ],
   "source": [
    "# ê¸°ì¡´ ìŠ¤ìº” ê²°ê³¼ ë¡œë“œ (LongArcì—ì„œ)\n",
    "start_years_path = os.path.join(source_dir, 'ticker_start_years.json')\n",
    "\n",
    "if os.path.exists(start_years_path):\n",
    "    with open(start_years_path, 'r') as f:\n",
    "        ticker_start_years = json.load(f)\n",
    "    print(f\"âœ… ê¸°ì¡´ ìŠ¤ìº” ê²°ê³¼ ë¡œë“œ: {len(ticker_start_years)}ê°œ ì¢…ëª©\")\n",
    "    skip_scan = True\n",
    "else:\n",
    "    print(\"ìŠ¤ìº” ê²°ê³¼ ì—†ìŒ. ìƒˆë¡œ ìŠ¤ìº” ì‹œì‘...\")\n",
    "    skip_scan = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì¢…ëª©ë³„ ë°ì´í„° ì‹œì‘ì¼ ìŠ¤ìº” (skip_scan=Falseì¼ ë•Œë§Œ ì‹¤í–‰)\n",
    "if not skip_scan:\n",
    "    import yfinance as yf\n",
    "    print(f\"ì´ ì¢…ëª© ìˆ˜: {len(sp500)}ê°œ\")\n",
    "    \n",
    "    data_range = []\n",
    "    \n",
    "    for ticker in tqdm(sp500, desc=\"ë°ì´í„° ë²”ìœ„ ìŠ¤ìº”\"):\n",
    "        try:\n",
    "            stock = yf.Ticker(ticker)\n",
    "            hist = stock.history(period=\"max\")\n",
    "            \n",
    "            if len(hist) > 0:\n",
    "                data_range.append({\n",
    "                    'ticker': ticker,\n",
    "                    'start_date': hist.index[0],\n",
    "                    'end_date': hist.index[-1],\n",
    "                    'years': (hist.index[-1] - hist.index[0]).days / 365\n",
    "                })\n",
    "        except Exception as e:\n",
    "            print(f\"{ticker} ì‹¤íŒ¨: {e}\")\n",
    "    \n",
    "    range_df = pd.DataFrame(data_range)\n",
    "    \n",
    "    # ì¢…ëª©ë³„ ì‹œì‘ ì—°ë„ ì¶”ì¶œ\n",
    "    range_df['start_year'] = pd.to_datetime(range_df['start_date']).dt.year\n",
    "    ticker_start_years = dict(zip(range_df['ticker'], range_df['start_year']))\n",
    "    \n",
    "    print(f\"\\nâœ… ìŠ¤ìº” ì™„ë£Œ: {len(ticker_start_years)}ê°œ ì¢…ëª©\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ì—°ë„ë³„ ì‚¬ìš© ê°€ëŠ¥ ì¢…ëª© ìˆ˜ ===\n",
      "2010ë…„: 435ê°œ ì¢…ëª©\n",
      "2011ë…„: 442ê°œ ì¢…ëª©\n",
      "2012ë…„: 451ê°œ ì¢…ëª©\n",
      "2013ë…„: 460ê°œ ì¢…ëª©\n",
      "2014ë…„: 466ê°œ ì¢…ëª©\n",
      "2015ë…„: 471ê°œ ì¢…ëª©\n",
      "2016ë…„: 477ê°œ ì¢…ëª©\n",
      "2017ë…„: 479ê°œ ì¢…ëª©\n",
      "2018ë…„: 482ê°œ ì¢…ëª©\n",
      "2019ë…„: 489ê°œ ì¢…ëª©\n"
     ]
    }
   ],
   "source": [
    "# ì—°ë„ë³„ ì‚¬ìš© ê°€ëŠ¥ ì¢…ëª© ìˆ˜ í™•ì¸\n",
    "print(\"=== ì—°ë„ë³„ ì‚¬ìš© ê°€ëŠ¥ ì¢…ëª© ìˆ˜ ===\")\n",
    "for year in range(2010, 2020):\n",
    "    available = [t for t, start in ticker_start_years.items() if start <= year]\n",
    "    print(f\"{year}ë…„: {len(available)}ê°œ ì¢…ëª©\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 2010ë…„ ì´í›„ ìƒì¥ ì¢…ëª© (77ê°œ) ===\n",
      "  CBOE: 2010ë…„\n",
      "  CHTR: 2010ë…„\n",
      "  CPAY: 2010ë…„\n",
      "  GNRC: 2010ë…„\n",
      "  GM: 2010ë…„\n",
      "  KKR: 2010ë…„\n",
      "  LYB: 2010ë…„\n",
      "  NXPI: 2010ë…„\n",
      "  TRGP: 2010ë…„\n",
      "  TSLA: 2010ë…„\n",
      "  APO: 2011ë…„\n",
      "  APTV: 2011ë…„\n",
      "  HCA: 2011ë…„\n",
      "  HII: 2011ë…„\n",
      "  KMI: 2011ë…„\n",
      "  ... ì™¸ 62ê°œ\n"
     ]
    }
   ],
   "source": [
    "# 2010ë…„ ì´í›„ ìƒì¥ ì¢…ëª© í™•ì¸\n",
    "recent_ipos = [(t, y) for t, y in ticker_start_years.items() if y >= 2010]\n",
    "recent_ipos = sorted(recent_ipos, key=lambda x: x[1])\n",
    "\n",
    "print(f\"\\n=== 2010ë…„ ì´í›„ ìƒì¥ ì¢…ëª© ({len(recent_ipos)}ê°œ) ===\")\n",
    "for ticker, year in recent_ipos[:15]:\n",
    "    print(f\"  {ticker}: {year}ë…„\")\n",
    "if len(recent_ipos) > 15:\n",
    "    print(f\"  ... ì™¸ {len(recent_ipos) - 15}ê°œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. ì´ë¯¸ ìˆ˜ì§‘ëœ ë°ì´í„° í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ê¸°ì¡´ ìˆ˜ì§‘ í˜„í™© ===\n",
      "ê°€ê²© ë°ì´í„° ìˆ˜ì§‘ë¨: 502ê°œ\n",
      "ì¬ë¬´ì œí‘œ ìˆ˜ì§‘ë¨: 503ê°œ\n",
      "ì™„ì „íˆ ìˆ˜ì§‘ë¨: 502ê°œ\n",
      "\n",
      "ìˆ˜ì§‘ í•„ìš”: 1ê°œ\n"
     ]
    }
   ],
   "source": [
    "# ì´ë¯¸ ìˆ˜ì§‘ëœ ì¢…ëª© í™•ì¸ (LongArcì—ì„œ)\n",
    "prices_dir = os.path.join(source_dir, 'prices')\n",
    "financials_dir = os.path.join(source_dir, 'financials')\n",
    "\n",
    "# ìˆ˜ì§‘ëœ ê°€ê²© ë°ì´í„°\n",
    "collected_prices = set()\n",
    "if os.path.exists(prices_dir):\n",
    "    collected_prices = {f.replace('.parquet', '') for f in os.listdir(prices_dir) if f.endswith('.parquet')}\n",
    "\n",
    "# ìˆ˜ì§‘ëœ ì¬ë¬´ì œí‘œ\n",
    "collected_financials = set()\n",
    "if os.path.exists(financials_dir):\n",
    "    collected_financials = {d for d in os.listdir(financials_dir) if os.path.isdir(os.path.join(financials_dir, d))}\n",
    "\n",
    "# ë‘˜ ë‹¤ ìˆëŠ” ì¢…ëª©\n",
    "fully_collected = collected_prices & collected_financials\n",
    "\n",
    "print(\"=== ê¸°ì¡´ ìˆ˜ì§‘ í˜„í™© ===\")\n",
    "print(f\"ê°€ê²© ë°ì´í„° ìˆ˜ì§‘ë¨: {len(collected_prices)}ê°œ\")\n",
    "print(f\"ì¬ë¬´ì œí‘œ ìˆ˜ì§‘ë¨: {len(collected_financials)}ê°œ\")\n",
    "print(f\"ì™„ì „íˆ ìˆ˜ì§‘ë¨: {len(fully_collected)}ê°œ\")\n",
    "\n",
    "# ìˆ˜ì§‘ í•„ìš” ì¢…ëª©\n",
    "to_collect = [t for t in sp500 if t not in fully_collected]\n",
    "print(f\"\\nìˆ˜ì§‘ í•„ìš”: {len(to_collect)}ê°œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. ë°ì´í„° ìˆ˜ì§‘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ë°ì´í„° ìˆ˜ì§‘:   0%|          | 0/1 [00:00<?, ?it/s]HTTP Error 404: {\"quoteSummary\":{\"result\":null,\"error\":{\"code\":\"Not Found\",\"description\":\"Quote not found for symbol: WBA\"}}}\n",
      "$WBA: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ê°€ê²© ë°ì´í„° ì—†ìŒ: WBA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HTTP Error 404: {\"quoteSummary\":{\"result\":null,\"error\":{\"code\":\"Not Found\",\"description\":\"Quote not found for symbol: WBA\"}}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ê°€ê²© ë°ì´í„° ì—†ìŒ: WBA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ë°ì´í„° ìˆ˜ì§‘: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "âœ… ìˆ˜ì§‘ ì™„ë£Œ\n",
      "==================================================\n",
      "ì„±ê³µ: 0/1\n",
      "ì‹¤íŒ¨: 1ê°œ\n",
      "ì†Œìš” ì‹œê°„: 0:00:01.916756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ë°°ì¹˜ ìˆ˜ì§‘ ì‹¤í–‰ (ìˆ˜ì§‘ í•„ìš”í•œ ê²½ìš°ë§Œ)\n",
    "if len(to_collect) == 0:\n",
    "    print(\"âœ… ëª¨ë“  ì¢…ëª© ì´ë¯¸ ìˆ˜ì§‘ë¨. ìŠ¤í‚µí•©ë‹ˆë‹¤.\")\n",
    "    failed = []\n",
    "    failed_reasons = {}\n",
    "    elapsed = datetime.now() - datetime.now()  # 0ì´ˆ\n",
    "else:\n",
    "    success = 0\n",
    "    failed = []\n",
    "    failed_reasons = {}\n",
    "\n",
    "    start_time = datetime.now()\n",
    "\n",
    "    for ticker in tqdm(to_collect, desc=\"ë°ì´í„° ìˆ˜ì§‘\"):\n",
    "        try:\n",
    "            # ê°€ê²© ë°ì´í„° (10ë…„)\n",
    "            prices = collector.collect_price_history(ticker, years=20)\n",
    "            \n",
    "            # ì¬ë¬´ì œí‘œ\n",
    "            financials = collector.collect_financials(ticker)\n",
    "            \n",
    "            if prices is not None and financials is not None:\n",
    "                success += 1\n",
    "            else:\n",
    "                failed.append(ticker)\n",
    "                if prices is None:\n",
    "                    failed_reasons[ticker] = \"ê°€ê²© ë°ì´í„° ì—†ìŒ\"\n",
    "                    print(f\"ê°€ê²© ë°ì´í„° ì—†ìŒ: {ticker}\")\n",
    "                else:\n",
    "                    failed_reasons[ticker] = \"ì¬ë¬´ì œí‘œ ì—†ìŒ\"\n",
    "                \n",
    "            # API ë¶€í•˜ ë°©ì§€\n",
    "            time.sleep(0.5)\n",
    "            \n",
    "        except Exception as e:\n",
    "            failed.append(ticker)\n",
    "            failed_reasons[ticker] = str(e)\n",
    "\n",
    "    elapsed = datetime.now() - start_time\n",
    "\n",
    "    print(f\"\\n\" + \"=\"*50)\n",
    "    print(f\"âœ… ìˆ˜ì§‘ ì™„ë£Œ\")\n",
    "    print(f\"=\"*50)\n",
    "    print(f\"ì„±ê³µ: {success}/{len(to_collect)}\")\n",
    "    print(f\"ì‹¤íŒ¨: {len(failed)}ê°œ\")\n",
    "    print(f\"ì†Œìš” ì‹œê°„: {elapsed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ì‹¤íŒ¨ ì¢…ëª© ===\n",
      "  WBA: ê°€ê²© ë°ì´í„° ì—†ìŒ\n"
     ]
    }
   ],
   "source": [
    "# ì‹¤íŒ¨ ì¢…ëª© ìƒì„¸\n",
    "if failed:\n",
    "    print(\"=== ì‹¤íŒ¨ ì¢…ëª© ===\")\n",
    "    for ticker in failed[:30]:  # ì²˜ìŒ 30ê°œë§Œ\n",
    "        reason = failed_reasons.get(ticker, \"ì•Œ ìˆ˜ ì—†ìŒ\")\n",
    "        print(f\"  {ticker}: {reason}\")\n",
    "    \n",
    "    if len(failed) > 30:\n",
    "        print(f\"  ... ì™¸ {len(failed) - 30}ê°œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. ìˆ˜ì§‘ ê²°ê³¼ ê²€ì¦"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ìµœì¢… ìˆ˜ì§‘ í˜„í™© ===\n",
      "ê°€ê²© ë°ì´í„°: 502ê°œ\n",
      "ì¬ë¬´ì œí‘œ: 503ê°œ\n",
      "ì™„ì „ ìˆ˜ì§‘: 502ê°œ\n",
      "\n",
      "S&P 500 ì»¤ë²„ë¦¬ì§€: 502/503 (99.8%)\n"
     ]
    }
   ],
   "source": [
    "# ìµœì¢… ìˆ˜ì§‘ í˜„í™©\n",
    "collected_prices = set()\n",
    "if os.path.exists(prices_dir):\n",
    "    collected_prices = {f.replace('.parquet', '') for f in os.listdir(prices_dir) if f.endswith('.parquet')}\n",
    "\n",
    "collected_financials = set()\n",
    "if os.path.exists(financials_dir):\n",
    "    collected_financials = {d for d in os.listdir(financials_dir) if os.path.isdir(os.path.join(financials_dir, d))}\n",
    "\n",
    "fully_collected = collected_prices & collected_financials\n",
    "\n",
    "print(\"=== ìµœì¢… ìˆ˜ì§‘ í˜„í™© ===\")\n",
    "print(f\"ê°€ê²© ë°ì´í„°: {len(collected_prices)}ê°œ\")\n",
    "print(f\"ì¬ë¬´ì œí‘œ: {len(collected_financials)}ê°œ\")\n",
    "print(f\"ì™„ì „ ìˆ˜ì§‘: {len(fully_collected)}ê°œ\")\n",
    "print(f\"\\nS&P 500 ì»¤ë²„ë¦¬ì§€: {len(fully_collected & set(sp500))}/{len(sp500)} ({100*len(fully_collected & set(sp500))/len(sp500):.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ITW ìƒ˜í”Œ ë°ì´í„° ===\n",
      "\n",
      "ğŸ“ˆ ê°€ê²© ë°ì´í„°: (5027, 7)\n",
      "   ê¸°ê°„: 2006-01-03 00:00:00 ~ 2025-12-24 00:00:00\n",
      "\n",
      "ğŸ“Š ì¬ë¬´ì œí‘œ:\n",
      "   balance_sheet_quarterly: (7, 83)\n",
      "   balance_sheet_annual: (5, 85)\n",
      "   income_stmt_annual: (4, 49)\n",
      "   cash_flow_annual: (5, 66)\n",
      "   info: 182 items\n",
      "   income_stmt_quarterly: (5, 41)\n",
      "   cash_flow_quarterly: (7, 64)\n"
     ]
    }
   ],
   "source": [
    "# ìƒ˜í”Œ ë°ì´í„° í™•ì¸\n",
    "sample_ticker = list(fully_collected)[0]\n",
    "\n",
    "print(f\"=== {sample_ticker} ìƒ˜í”Œ ë°ì´í„° ===\")\n",
    "\n",
    "# ê°€ê²© ë°ì´í„°\n",
    "prices = collector.load_price_data(sample_ticker)\n",
    "print(f\"\\nğŸ“ˆ ê°€ê²© ë°ì´í„°: {prices.shape}\")\n",
    "print(f\"   ê¸°ê°„: {prices['Date'].min()} ~ {prices['Date'].max()}\")\n",
    "\n",
    "# ì¬ë¬´ì œí‘œ\n",
    "financials = collector.load_financials(sample_ticker)\n",
    "print(f\"\\nğŸ“Š ì¬ë¬´ì œí‘œ:\")\n",
    "for key, val in financials.items():\n",
    "    if isinstance(val, pd.DataFrame):\n",
    "        print(f\"   {key}: {val.shape}\")\n",
    "    elif isinstance(val, dict):\n",
    "        print(f\"   {key}: {len(val)} items\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. ìˆ˜ì§‘ ê²°ê³¼ ì €ì¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ìˆ˜ì§‘ ë¡œê·¸ ì €ì¥: /Users/kuka/5X Finder/data/raw/collection_log.json\n"
     ]
    }
   ],
   "source": [
    "# ìˆ˜ì§‘ ë¡œê·¸ ì €ì¥ (5X Finderë¡œ)\n",
    "collection_log = {\n",
    "    'timestamp': datetime.now().isoformat(),\n",
    "    'version': 'v2',\n",
    "    'total_tickers': len(sp500),\n",
    "    'collected': len(fully_collected),\n",
    "    'failed': failed,\n",
    "    'failed_reasons': failed_reasons,\n",
    "    'elapsed_seconds': elapsed.total_seconds() if elapsed else 0\n",
    "}\n",
    "\n",
    "log_path = os.path.join(output_dir, 'collection_log.json')\n",
    "with open(log_path, 'w') as f:\n",
    "    json.dump(collection_log, f, indent=2, default=str)\n",
    "\n",
    "print(f\"âœ… ìˆ˜ì§‘ ë¡œê·¸ ì €ì¥: {log_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì¢…ëª©ë³„ ì‹œì‘ ì—°ë„ ì €ì¥: /Users/kuka/5X Finder/data/raw/ticker_start_years.json\n",
      "   ì´ 502ê°œ ì¢…ëª©\n"
     ]
    }
   ],
   "source": [
    "# ì¢…ëª©ë³„ ë°ì´í„° ì‹œì‘ ì—°ë„ ì €ì¥ (5X Finderë¡œ)\n",
    "start_years_output = os.path.join(output_dir, 'ticker_start_years.json')\n",
    "with open(start_years_output, 'w') as f:\n",
    "    json.dump(ticker_start_years, f, indent=2)\n",
    "\n",
    "print(f\"âœ… ì¢…ëª©ë³„ ì‹œì‘ ì—°ë„ ì €ì¥: {start_years_output}\")\n",
    "print(f\"   ì´ {len(ticker_start_years)}ê°œ ì¢…ëª©\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. ìš”ì•½"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "ğŸ“‹ Data Collection ì™„ë£Œ\n",
      "==================================================\n",
      "\n",
      "ğŸ“Š ìˆ˜ì§‘ í˜„í™©\n",
      "  S&P 500 ì»¤ë²„ë¦¬ì§€: 502/503 (99.8%)\n",
      "  ì‹¤íŒ¨ ì¢…ëª©: 1ê°œ\n",
      "\n",
      "ğŸ“ ì €ì¥ëœ íŒŒì¼ (/Users/kuka/5X Finder/data/raw)\n",
      "  - collection_log.json (ìˆ˜ì§‘ ë¡œê·¸)\n",
      "  - ticker_start_years.json (ë™ì  í•„í„°ë§ìš©)\n",
      "\n",
      "ğŸ”œ ë‹¤ìŒ ë‹¨ê³„\n",
      "  03_feature_engineering.ipynb - Feature ê³„ì‚° (ë™ì  í•„í„°ë§)\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*50)\n",
    "print(\"ğŸ“‹ Data Collection ì™„ë£Œ\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(f\"\\nğŸ“Š ìˆ˜ì§‘ í˜„í™©\")\n",
    "print(f\"  S&P 500 ì»¤ë²„ë¦¬ì§€: {len(fully_collected)}/{len(sp500)} ({100*len(fully_collected)/len(sp500):.1f}%)\")\n",
    "print(f\"  ì‹¤íŒ¨ ì¢…ëª©: {len(failed)}ê°œ\")\n",
    "\n",
    "print(f\"\\nğŸ“ ì €ì¥ëœ íŒŒì¼ ({output_dir})\")\n",
    "print(f\"  - collection_log.json (ìˆ˜ì§‘ ë¡œê·¸)\")\n",
    "print(f\"  - ticker_start_years.json (ë™ì  í•„3í„°ë§ìš©)\")\n",
    "\n",
    "print(f\"\\nğŸ”œ ë‹¤ìŒ ë‹¨ê³„\")\n",
    "print(f\"  03_feature_engineering.ipynb - Feature ê³„ì‚° (ë™ì  í•„í„°ë§)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
